{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import sys\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName('model testing') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "#Reading the arguments and storing them in variables\n",
    "project_name=sys.argv[1]\n",
    "dataset_name=sys.argv[2]\n",
    "bucket_name=sys.argv[3]\n",
    "user_name=sys.argv[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkDF = spark.read.options(inferSchema = True, header= True).csv('gs://'+bucket_name+'/customer-churn-prediction-vertex-ai/01-datasets/customer_churn_test_model_data.csv')\n",
    "\n",
    "\n",
    "sparkDF=sparkDF.withColumn(\"Partner\",sparkDF.Partner.cast('string')).withColumn(\"Dependents\",sparkDF.Dependents.cast('string')).withColumn(\"PhoneService\",sparkDF.PhoneService.cast('string')).withColumn(\"PaperlessBilling\",sparkDF.PaperlessBilling.cast('string'))\n",
    "sparkDF=sparkDF.head(1)\n",
    "sparkDF=spark.createDataFrame(sparkDF)\n",
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "rf_model = PipelineModel.load(os.path.join('gs://'+bucket_name+'/customer-churn-prediction-vertex-ai/'+user_name+'_churn_model/model_files'))\n",
    "\n",
    "#Replacing 'No internet service' to No for the following columns\n",
    "replace_cols = [ 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                'TechSupport','StreamingTV', 'StreamingMovies']\n",
    "#replace values\n",
    "for col_name in replace_cols:\n",
    "    dfwithNo = sparkDF.withColumn(col_name, when(col(col_name)== \"No internet service\",\"No\").otherwise(col(col_name)))\n",
    "    sparkDF = dfwithNo\n",
    "\n",
    "predic = rf_model.transform(dfwithNo)\n",
    "\n",
    "\n",
    "spark.conf.set(\"parentProject\", project_name)\n",
    "bucket = bucket_name\n",
    "spark.conf.set(\"temporaryGcsBucket\",bucket)\n",
    "predic.write.format('bigquery') \\\n",
    ".mode(\"overwrite\")\\\n",
    ".option('table', project_name+':'+dataset_name+'.'+user_name+'_test_output') \\\n",
    ".save()\n",
    "\n",
    "print(predic.show(truncate=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark [conda env:root] * (Local)",
   "language": "python",
   "name": "local-conda-root-pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "serverless_spark": "{\"name\":\"projects/tgs-internal-gcpgtminit-dev-01/locations/us-central1/sessions/kkvertex-session\",\"uuid\":\"8e15d845-a08f-466e-9d21-c2103cb43fa4\",\"createTime\":\"2022-05-11T06:20:48.854599Z\",\"jupyterSession\":{},\"spark\":{},\"runtimeInfo\":{\"endpoints\":{\"Spark History Server\":\"https://di4wwkrkine4zkd3ekrinmlc4q-dot-us-central1.dataproc.googleusercontent.com/sparkhistory/\"},\"outputUri\":\"https://ixd634dxyvay7iwlnyfx6h5ek4-dot-us-central1.dataproc.googleusercontent.com/gateway/default/jupyter/lab/\"},\"state\":\"ACTIVE\",\"stateTime\":\"2022-05-11T06:21:46.781294Z\",\"creator\":\"198454710197-compute@developer.gserviceaccount.com\",\"runtimeConfig\":{\"properties\":{\"spark:spark.jars\":\"gs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.12-0.22.2.jar\",\"spark:spark.executor.instances\":\"2\",\"spark:spark.driver.cores\":\"4\",\"spark:spark.executor.cores\":\"4\",\"spark:spark.eventLog.dir\":\"gs://bq_serverless_spark/phs/8e15d845-a08f-466e-9d21-c2103cb43fa4/spark-job-history\"}},\"environmentConfig\":{\"executionConfig\":{\"subnetworkUri\":\"subnet-covid\"},\"peripheralsConfig\":{\"sparkHistoryServerConfig\":{\"dataprocCluster\":\"projects/tgs-internal-gcpgtminit-dev-01/regions/us-central1/clusters/spark-phs\"}}}}",
  "serverless_spark_kernel_name": "remote-3bf6a892678aed767accba03-pyspark"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
